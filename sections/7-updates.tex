% !TEX root = ../main.tex
\section{Updates}
\label{sec:updates}

Real-world data is rarely static, which is exactly the scenario that \dcv faces at Merck and the MIT Data Warehouse.  We consider three types of updates.

\stitle{(1) Insertions/deletions on source tables.} This happens when there is a change to a table, \eg insertion of a new procurement record in the MIT Data Warehouse. This may also happen when some data sources are cleaned (see Section~\ref{sec:curating}).


\stitle{(2) Replacement of source tables.} Large companies typically rely on both internal and external information to build their knowledge bases. For instance, Merck collects published standard medical names from the World Health Organization (WHO) to help construct their own ontology. These data sources are updated periodically by WHO.  Sometimes, even the format may be changed, e.g., from a JSON file to a CSV file.


\stitle{(3) Updating MVs.} MVs might be created based on other MVs.  Since cleaning effort can happen at any place in a query plan, MVs may need to be updated.


%In response to the above three types of updates, 
\dcv uses three corresponding strategies to cater for these updates.


\stitle{(i) MV maintenance.} \dcv will leverage mature techniques for maintaining materialized views (see~\cite{DBLP:journals/debu/GuptaM95} for a survey).  In this way, \dcv incrementally propagates updates through the data curation pipeline to update downstream MVs.




\stitle{(ii) Provenance management.}  In case (2) above, the human effort to update and clean MVs may be daunting. In this case, MVs should be discarded rather than updated. Naturally, there is a need for a workflow component that supports data versioning and branching operations. \dcv will leverage Decibel~\cite{DBLP:journals/pvldb/MaddoxGEMPD16}, a system developed at MIT for this purpose.

\stitle{(iii) Descriptive and prescriptive data cleaning.} When a scientist updates an MV (case 3) above), this will trigger the update propagation to descendant MVs, as well as back upstream to data sources, if possible. To perform this propagation, we plan to leverage the techniques in PDC~\cite{DBLP:conf/sigmod/ChalamallaIOP14}, a system developed by QCRI and Waterloo.


%As data appears incrementally, we need an incremental inclusion dependency algorithm. Extending our algorithms in Section~\ref{subsec:eind} is a project we are currently working on.

