% !TEX root = ../main.tex

\begin{abstract}
In many organizations, it is often challenging for users to find relevant data for  specific tasks, since the data is usually scattered across the enterprise and often inconsistent. In fact, data scientists routinely report that the majority of their effort is spent finding, cleaning, integrating, and accessing data of interest to a task at hand. 
In order to decrease the ``grunt work'' needed to facilitate the analysis of data ``in the wild'', we present \dcv, an end-to-end big data management system. 
\dcv has a {\em linkage graph computation} module 
%to build a linkage graph for the data 
and a {\em data discovery} module which utilizes the linkage graph to help identify data that is relevant to user tasks. 
We also use the linkage graph to link the discovered data and query it using a polystore architecture,
which federates query processing across disparate systems.
The polystore query also integrates data cleaning operations.
Since in practice, different tasks might invoke the above modules in different orders, and might be iterative,
\dcv embeds a {\em workflow} engine. This engine enables the arbitrary composition of different modules, as well as the handling of data updates. 
We have deployed our preliminary \dcv system in two institutions, MIT and Merck. Users have given us positive feedback and indicated that the system indeed shortened their time and effort to find, prepare, and analyze the data.
\end{abstract}