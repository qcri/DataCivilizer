% !TEX root = ../main.tex

\begin{abstract}

In many organizations, it is often challenging for users to find relevant data for  specific tasks, since the data is usually scattered across the enterprise and often inconsistent. In fact, data scientists routinely report that the majority of their effort is spent finding, cleaning, integrating, and accessing data of interest to a task at hand. 
In order to decrease the ``grunt work'' needed to facilitate the analysis of data ``in the wild'', we present \dcv, an end-to-end big data management system. \dcv has a {\em linkage graph computation} module to build a linkage graph for the data and a {\em data discovery} module which utilizes the linkage graph to help identify data that is relevant to user tasks. It also uses the linkage graph to link the discovered data, so it can be queried, along with a polystore DBMS for query execution, which federates query processing across disparate systems. In addition, \dcv integrates data cleaning operations into query processing. As in practice, different tasks might invoke the above tasks in different orders and might be iterative, \dcv embeds a {\em workflow} engine which enables the arbitrary composition of different modules, as well as the handling of data updates. We have deployed our preliminary \dcv system in two institutions, MIT and Merck. Users have given us positive feedback and indicated that the system indeed shortened their time and effort to find, prepare, and analyze the data.

\end{abstract}