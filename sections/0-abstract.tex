% !TEX root = ../main.tex
\begin{abstract}
In many organizations, it is often challenging for users to find relevant data for specific tasks, since the data is usually scattered across the enterprise and often inconsistent. In fact, data scientists routinely report that the majority of their effort is spent finding, cleaning, integrating, and accessing data of interest to a task at hand. 
 In order to decrease the ``grunt work'' needed to facilitate the analysis of data ``in the wild'', we present \dcv, an end-to-end big data management system. \dcv has a {\em linkage graph computation} module to build a linkage graph for the data and a {\em data discovery} module which utilizes the linkage graph to help identify data that is relevant to user tasks. It also uses the linkage graph to join the discovered data, so it can be queried, along with a polystore DBMS for query execution, which federates query processing across disparate systems. In addition, \dcv integrates data cleaning operations into query processing. Because different users need to invoke the above tasks in different orders, \dcv embeds a {\em workflow} engine which enables the arbitrary composition of different modules, as well as the handling of data updates. We have deployed our preliminary \dcv system in two institutions, MIT and Merck and describe initial positive experiences that show the system shortens the time and effort required to find, prepare, and analyze data.
\end{abstract}