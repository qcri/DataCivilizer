% !TEX root = ../main.tex
\section{Data Stitcher}
\label{sec:stitching}

\newcommand{\eind}{error-robust inclusion dependency\xspace}
\newcommand{\ind}{inclusion dependency\xspace}
\newcommand{\R}{\ensuremath{R}\xspace}
\renewcommand{\S}{\ensuremath{S}\xspace}
\newcommand{\X}{\ensuremath{X}\xspace}
\newcommand{\Y}{\ensuremath{Y}\xspace}
\newcommand{\RX}{\ensuremath{\R[\X]}\xspace}
\newcommand{\SY}{\ensuremath{\S[\Y]}\xspace}
\newcommand{\IND}{IND\ensuremath{(\X,\Y)}\xspace}
\newcommand{\EIND}{\texttt{EIND}\ensuremath{(\RX,\SY)}\xspace}
\newcommand\subsetsim{\mathrel{%
  \ooalign{\raise0.3ex\hbox{$\subset$}\cr\hidewidth\raise-0.6ex\hbox{\scalebox{0.8}{$\sim$}}\hidewidth\cr}}}
\newcommand{\G}{\ensuremath{G}\xspace}
\newcommand{\E}{\ensuremath{E}\xspace}
\newcommand{\U}{\ensuremath{U}\xspace}
\newcommand{\V}{\ensuremath{V}\xspace}

\newtheorem{theorem}{Theorem}
\newtheorem{example}{Example}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}



%\dong{Maybe we should move the cleanliness estimation and querying things to enhanced data stitching section?}

%\dong{I am gonna to do a more detailed survey on inclusion dependency.} 

%, which we discuss in Section~\ref{subsec:incremental}

%\nan{It is better to connect the section by using the context of Data Civilizer, not a general motivation. That is, instead of talking about large corporations, it is better to focus on what is the output of Discovery component.}
%\nan{Do we want to say that {\bf Data Stitcher = (Advanced) Inclusion Dependency discovery}?}

As data in large corporations are typically scattered everywhere, to better manage and use the data, it is crucial to link them together. Given a bunch of related tables without schema information, data stitcher builds a (join) graph on top of them, where each vertex represents a table and each directed edge represents a join path between two tables with necessary information, such as primary key and foreign key. To this end, data stitching first utilizes the inclusion dependency to find the candidate FK-PK relationship and then refines them to build the join graph. However, as we all known, data in the wild is rather dirty. The dirty data contaminates the inclusion dependency in two ways: make fewer keys overlap and make keys not exactly match. To tolerate errors, we extend the traditional inclusion dependency by both key coverage and text similarity and propose the \emph{\eind}. 

%in Section~\ref{subsec:eind}. We design an efficient and scalable algorithm to find the \eind. Secondly, as new data comes to us continuously, inclusion dependency must be found incrementally. 


%1. Limit the search space

%2. Tolerate errors in includency dependency

%3. Estimate the cleanings in join path

%4. Querying the graph


\subsection{Error-Robust Inclusion Dependency}\label{subsec:eind}

%\nan{What I want to convey is that the main challenge of Data Stitcher is not inclusion dependency. The challenge should be, given all possible ways of stitching related tables together, how to interact with users to give them the stitched results, i.e., materialized views, that the users want.}



Foreign key is one of the most important schema information in managing and using data, which is typically missing in real world. The foreign key and primary key relations are usually identified by inclusion dependency. However, data in the wild is full of errors, such as inconsistence and different formats. This yields to the requirement of error tolerating in inclusion dependency. We observe that the errors in data can contaminate the inclusion dependency in two ways. First, they make the corresponding primary keys and foreign keys not match exactly. Second, they make the foreign keys not all covered by the primary keys. To address these issues, we design an error-robust inclusion dependency which enhances the traditional inclusion dependency with value coverage and text similarity. The main idea behind the error-robust inclusion dependency is that we use the text similarity between the keys to estimate the possibility of they represent the same object. As each distinct foreign key can only be mapped to one primary key and vice versa, we further use the maximum weighted bipartite matching to align the primary keys and the foreign keys. Note it is challenging to efficiently find all the error-robust inclusion dependencies within a bunch of tables, as the input tables can be large and both finding the maximum weighted bipartite matching and calculating the text similarities between all the primary keys and foreign keys are time consuming.



%Given two projections \RX and \SY, we build a weighted bigraph $\G=((\U,\V),\E)$ based on the projections. There is a bijection between the vertexes in \U and the distinct instances in \RX, i.e., each vertex $u$ in $\U$ maps to a distinct instance in \RX and vice versa. This also applies to the vertex set \V and the distinct instances in \SY. For any vertexes $u\in\U$ and $v\in\V$, there is a weighted edge $e=(u,v)\in\E$ where the weight $w_e$ is defined by the text similarity between their corresponding instance values, such as Jaccard similarity and edit similarity. The \emph{maximum bipartite matching} of \G is a set of edges $\E_{max}\subseteq\E$ which satisfies (1) any two edges in it share no common vertex and (2) the sum of edge weights is maximum. Let $\EIND=\frac{\sum_{e\in\E_{max}}w_e}{|\U|}$. Then \EIND is proportional to the chance of an inclusion dependency from $\RX$ to $\SY$. Given an error-tolerating threshold $\delta$, we formally define the \eind as follows.

\iffalse
\begin{definition}[Error-Robust Inclusion Dependency]
Given two projections \RX and \SY on relational tables and an error-tolerating threshold $\delta$, there is an error-robust inclusion dependency from \X to \Y when $\EIND\geq\delta$.
\end{definition}

\dong{To add an example here.}
\fi

We can apply different text similarity functions on different fields of the key. As it requires all the fields in two keys to be match in inclusion dependency, we combine the text similarities in different fields of the instances by multiplying them. For example, given two keys \textsf{(SIGMOD Conference, Sam Madden, San Francisco)} and \textsf{(SIGMOD Conference 2016, Samuel Madden, San Francisco)}. Suppose that we uses Jaccard similarity to evaluate the first field and edit similarity to evaluate the second field. Then we can combine the text similarities as $\frac{2}{3}*\frac{7}{10}*1=0.47$.


As the data comes to us gradually while finding the inclusion dependency, especially the error-robust inclusion dependency, is time consuming, it is necessary to have the \eind incrementally founded. Moreover, the inclusion dependency does not necessary yields primary key and foreign key relationship, further techniques to eliminates the false positives are needed. After that, it is straightforward to construct the join graph using the primary keys and foreign keys: each table is a vertex and there is an edge between two vertexes only if there exists a primary key and foreign key relationship between them. 


\subsection{Refine Candidate FK-PK Relationships}

The error-robust inclusion dependency gives us a bunch of candidate foreign key and primary key (PK-FK) relationships. We can apply existing machine learning method to remove the false positives from the results. 




\iffalse
\subsection{Query the Join Graph}\label{subsec:query}

Once the join graph is constructed, the users can query it in various way. Among them, one of the most important one is to.

The essential way to query the join graph is taking several vertexes and find an subgraph containing all the query vertexes.

The user can specify several attributes which compose a \emph{query schema}. 

Given a collection of attributes, we aim to find a subgraph that contains all the corresponding vertexes. 

%\subsection{Cleanliness Estimation}
%finding ind in a scalable way
%column de-duplication
\fi